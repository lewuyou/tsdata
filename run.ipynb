{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
    "from exp.exp_imputation import Exp_Imputation\n",
    "from exp.exp_short_term_forecasting import Exp_Short_Term_Forecast\n",
    "from exp.exp_anomaly_detection import Exp_Anomaly_Detection\n",
    "from exp.exp_classification import Exp_Classification\n",
    "from data_provider.data_creat import *\n",
    "import akshare as ak\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    '''基本配置'''\n",
    "    # 选项：[long_term_forecast, short_term_forecast, imputation, classification, anomaly_detection]')\n",
    "    task_name = 'long_term_forecast'\n",
    "    is_training = 1\n",
    "    model_id = 'Stock_96_96'\n",
    "    # 模型名称，选项：[Autoformer, Transformer, TimesNet]\n",
    "    model = 'TimesNet'\n",
    "    \n",
    "    '''股票数据获取'''\n",
    "    fuquan = 'hfq'# 设置复权方式,adjust=空选择的不复权，qfq是前复权，应该用hfq后复权来进行量化分析\n",
    "    period = 'daily' # 拉取时间周期{'daily', 'weekly', 'monthly'}\n",
    "    start_date = '20151201'  # 20151201 下载数据的开始日期,0就是公司上市时间\n",
    "    end_date = '-1'  # 下载数据的结束日期,如果0则到最后一天,如果-1是昨天.\n",
    "    final_data_feat =  ['index', 'Volume','Tom_Chg'] # 删除不需要列的标签\n",
    "    label_n = 5 # 预测未来连续多少天的收益率\n",
    "    # 标签是否替换成1或者0\n",
    "    zhangfu = 0.01  # 预测涨幅大于等于3%的为1，小于3%的为0\n",
    "    label_ch = True  # 如果是True ，预测n天以后上涨大于变量zhangfu为1，小于为0\n",
    "    \n",
    "    \n",
    "    '''数据加载'''\n",
    "    # 数据集类型,选项：[ETTh1,ETTh2,ETTm1,ETTm2,custom,m4,PSM,MSL,SMAP,SMD,SWAT,UEA]\n",
    "    data = 'custom'\n",
    "    root_path = './dataset/Stock/'\n",
    "    data_path = 'Stock.csv'\n",
    "    # 数据拼接不同股票中间添加间隔的数量\n",
    "    data_addzero = 20\n",
    "    # 预测任务 M:多变量预测多变量, S:单变量预测单变量, MS:多变量预测单变量\n",
    "    features = 'MS'\n",
    "    # 目标列名，S或MS任务中的目标特征\n",
    "    target = 'OT'\n",
    "    # 时间采集粒度，选项：[s:秒, t:分钟, h:小时, d:天, b:工作日, w:周, m:月]\n",
    "    freq = 'd'\n",
    "    # 模型检查点的位置\n",
    "    checkpoints = './checkpoints/'\n",
    "\n",
    "    '''预测任务'''\n",
    "    # 输入序列长度,这是用于模型训练的输入序列的长度\n",
    "    seq_len = 60\n",
    "    # 开始标记长度,这是模型输出目标中有标签数据的长度，类似于滑动窗口的长度\n",
    "    label_len = 20\n",
    "    # 预测序列长度\n",
    "    pred_len = 1\n",
    "    # 季节模式（针对M4数据集）\n",
    "    seasonal_patterns = 'Monthly'\n",
    "    inverse = False    # 反转输出数据\n",
    "\n",
    "    '''插补任务'''\n",
    "    # 插补任务中数据丢失率\n",
    "    mask_rate = 0.25\n",
    "\n",
    "    '''异常检测任务'''\n",
    "    # 异常检测中异常点占比\n",
    "    anomaly_ratio = 0.25\n",
    "\n",
    "    '''模型定义'''\n",
    "    # TimesBlock 中傅里叶变换,频率排名前k个周期\n",
    "    top_k = 5\n",
    "    # Inception 中卷积核个数\n",
    "    num_kernels = 6\n",
    "    # encoder 输入特征数\n",
    "    enc_in = 38\n",
    "    # decoder 输入特征数\n",
    "    dec_in = 38\n",
    "    # 输出通道数\n",
    "    c_out = 38\n",
    "    # 线性层隐含神经元个数\n",
    "    d_model = 32\n",
    "    # FFN 层隐含神经元个数\n",
    "    d_ff = 32\n",
    "    # 多头注意力机制\n",
    "    n_heads = 8\n",
    "    # encoder 层数\n",
    "    e_layers = 2\n",
    "    # decoder 层数\n",
    "    d_layers = 1\n",
    "    # 滑动窗口长度\n",
    "    moving_avg = 20\n",
    "    # 对 Q 进行采样，对 Q 采样的因子数\n",
    "    factor = 3\n",
    "    # 是否下采样操作 pooling\n",
    "    distil = True\n",
    "    # dropout 率\n",
    "    dropout = 0.1\n",
    "    # 时间特征嵌入方式,选项：[timeF, fixed, learned]\n",
    "    embed = 'timeF'\n",
    "    # 激活函数类型\n",
    "    activation = 'gelu'\n",
    "    # 是否输出 attention\n",
    "    output_attention = False\n",
    "\n",
    "    '''优化'''\n",
    "    # 并行核心数\n",
    "    num_workers = 10\n",
    "    # 实验轮数\n",
    "    itr = 1\n",
    "    # 训练迭代次数\n",
    "    train_epochs = 500\n",
    "    # batch size 大小\n",
    "    batch_size = 60\n",
    "    # early stopping 机制容忍次数\n",
    "    patience = 5\n",
    "    # 学习率\n",
    "    learning_rate = 0.0001\n",
    "    # 实验描述\n",
    "    des = 'stock'\n",
    "    # 损失函数\n",
    "    loss = 'MSE'\n",
    "    # 学习率下降策略\n",
    "    lradj = 'type1'\n",
    "    # 使用混合精度训练\n",
    "    use_amp = False\n",
    "\n",
    "    '''GPU'''\n",
    "    # 使用 gpu\n",
    "    use_gpu = True\n",
    "    gpu = 0\n",
    "    # 使用多个 gpus\n",
    "    use_multi_gpu = False\n",
    "    # 多 gpu 的设备 id\n",
    "    devices = '0,1,2,3'\n",
    "\n",
    "    '''去平稳化投影仪参数'''\n",
    "    # 投影仪的隐藏层维度（列表）\n",
    "    p_hidden_dims = [128, 128]\n",
    "    # 投影仪中的隐藏层数\n",
    "    p_hidden_layers = 2\n",
    "\n",
    "\n",
    "# 创建参数对象\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_down = ak.stock_cy_a_spot_em() # 创业板实时数据\n",
    "stock_list = stock_down[~stock_down['名称'].str.contains(\"退|ST\") & (stock_down['流通市值'] <= 1e11) & (stock_down['总市值'] >= 45e8)] # 去除退市和ST股票\n",
    "# 保存数据，编码格式为utf-8\n",
    "file_name = 'Stock_list.csv'\n",
    "stock_list.to_csv(args.root_path + file_name,index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取数据时间为： 20151201 - 20231220\n",
      "原始数据形状： (1649, 9)\n",
      "添加数据以后形状： (1649, 36)\n",
      "添加label以后数据形状: (1649, 38)\n",
      "删除指定行、列后数据形状:  (1619, 36)\n",
      "处理进度: 1/608 (0.16%)\n",
      "当前all_data的形状: (1639, 36)\n",
      "获取数据时间为： 20151201 - 20231220\n",
      "原始数据形状： (596, 9)\n",
      "添加数据以后形状： (596, 36)\n",
      "添加label以后数据形状: (596, 38)\n",
      "删除指定行、列后数据形状:  (566, 36)\n",
      "处理进度: 2/608 (0.33%)\n",
      "当前all_data的形状: (2225, 36)\n",
      "获取数据时间为： 20151201 - 20231220\n",
      "原始数据形状： (996, 9)\n",
      "添加数据以后形状： (996, 36)\n",
      "添加label以后数据形状: (996, 38)\n",
      "删除指定行、列后数据形状:  (966, 36)\n",
      "处理进度: 3/608 (0.49%)\n",
      "当前all_data的形状: (3211, 36)\n",
      "获取数据时间为： 20151201 - 20231220\n",
      "原始数据形状： (120, 9)\n",
      "股票代码 301397 的数据长度小于300,跳过此次循环。\n",
      "获取数据时间为： 20151201 - 20231220\n",
      "原始数据形状： (1630, 9)\n",
      "添加数据以后形状： (1630, 36)\n",
      "添加label以后数据形状: (1630, 38)\n",
      "删除指定行、列后数据形状:  (1600, 36)\n",
      "处理进度: 5/608 (0.82%)\n",
      "当前all_data的形状: (4831, 36)\n",
      "获取数据时间为： 20151201 - 20231220\n",
      "原始数据形状： (1719, 9)\n",
      "添加数据以后形状： (1719, 36)\n",
      "添加label以后数据形状: (1719, 38)\n",
      "删除指定行、列后数据形状:  (1689, 36)\n",
      "处理进度: 6/608 (0.99%)\n",
      "当前all_data的形状: (6540, 36)\n",
      "获取数据时间为： 20151201 - 20231220\n",
      "原始数据形状： (1894, 9)\n",
      "添加数据以后形状： (1894, 36)\n",
      "添加label以后数据形状: (1894, 38)\n",
      "删除指定行、列后数据形状:  (1864, 36)\n",
      "处理进度: 7/608 (1.15%)\n",
      "当前all_data的形状: (8424, 36)\n",
      "获取数据时间为： 20151201 - 20231220\n",
      "原始数据形状： (1655, 9)\n",
      "添加数据以后形状： (1655, 36)\n",
      "添加label以后数据形状: (1655, 38)\n",
      "删除指定行、列后数据形状:  (1625, 36)\n",
      "处理进度: 8/608 (1.32%)\n",
      "当前all_data的形状: (10069, 36)\n",
      "获取数据时间为： 20151201 - 20231220\n",
      "原始数据形状： (1961, 9)\n",
      "添加数据以后形状： (1961, 36)\n",
      "添加label以后数据形状: (1961, 38)\n",
      "删除指定行、列后数据形状:  (1931, 36)\n",
      "处理进度: 9/608 (1.48%)\n",
      "当前all_data的形状: (12020, 36)\n",
      "获取数据时间为： 20151201 - 20231220\n",
      "原始数据形状： (1660, 9)\n",
      "添加数据以后形状： (1660, 36)\n",
      "添加label以后数据形状: (1660, 38)\n",
      "删除指定行、列后数据形状:  (1630, 36)\n",
      "处理进度: 10/608 (1.64%)\n",
      "当前all_data的形状: (13670, 36)\n",
      "数据保存完毕。\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "all_data_raw = pd.DataFrame()  # 初始化一个空的 DataFrame 用于存储原始数据\n",
    "all_data_scaled = pd.DataFrame()  # 初始化一个空的 DataFrame 用于存储标准化后的数据\n",
    "processed_count = 0  # 初始化计数器\n",
    "total_count = len(stock_list[\"代码\"].values)  # 获取总股票数量\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in stock_list[\"代码\"].values[400:410]:\n",
    "    NUM = i\n",
    "    try:\n",
    "        # 下载原始数据\n",
    "        raw_data = download_data(NUM, args)\n",
    "        # 更新已处理股票数量计数器\n",
    "        processed_count += 1\n",
    "        # 检查数据长度，如果小于300则跳过此次循环\n",
    "        if raw_data.shape[0] < 300:\n",
    "            print(f\"股票代码 {NUM} 的数据长度小于300,跳过此次循环。\")\n",
    "            continue\n",
    "        \n",
    "        # 拼接数据，添加各种参数\n",
    "        ad_data = add_data(raw_data.copy(), args)\n",
    "        # 添加预测标签\n",
    "        ot_data = add_label(ad_data.copy(), args)\n",
    "        # 删除无效数据\n",
    "        su_data = sub_data(ot_data.copy(), args)\n",
    "\n",
    "        # 存储未经标准化的数据\n",
    "        all_data_raw = pd.concat([all_data_raw, su_data], ignore_index=True)\n",
    "\n",
    "        # 标准化处理\n",
    "        # scaler = StandardScaler()\n",
    "        non_time_columns = su_data.columns[1:-1]  # 假设时间列是第一列\n",
    "        su_data_scaled = su_data.copy()\n",
    "        su_data_scaled[non_time_columns] = scaler.fit_transform(su_data[non_time_columns])\n",
    "\n",
    "        # 存储经过标准化的数据\n",
    "        all_data_scaled = pd.concat([all_data_scaled, su_data_scaled], ignore_index=True)\n",
    "\n",
    "        # 如果args.data_addzero为True，并且all_data不是空的，先插入20行全为0的数据\n",
    "        if args.data_addzero and not all_data_raw.empty:\n",
    "            zero_data_raw = pd.DataFrame(0, index=range(args.data_addzero), columns=all_data_raw.columns)\n",
    "            all_data_raw = pd.concat([all_data_raw, zero_data_raw], ignore_index=True)\n",
    "\n",
    "        # 如果args.data_addzero为True，并且all_data_scaled不是空的，先插入20行全为0的数据\n",
    "        if args.data_addzero and not all_data_scaled.empty:\n",
    "            zero_data_scaled = pd.DataFrame(0, index=range(args.data_addzero), columns=all_data_scaled.columns)\n",
    "            all_data_scaled = pd.concat([all_data_scaled, zero_data_scaled], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"处理股票代码 {NUM} 时出现错误: {e}\")\n",
    "        continue\n",
    "\n",
    "    # 计算并打印处理进度\n",
    "    progress = processed_count / total_count\n",
    "    print(f\"处理进度: {processed_count}/{total_count} ({progress:.2%})\")\n",
    "    print(f\"当前all_data的形状: {all_data_scaled.shape}\")\n",
    "\n",
    "# 保存原始数据到 CSV 文件\n",
    "file_name_raw = \"all_data_raw.csv\"\n",
    "all_data_raw.to_csv(args.root_path + file_name_raw, index=False)\n",
    "\n",
    "# 保存标准化后的数据到 CSV 文件\n",
    "file_name_scaled = \"all_data_scaled.csv\"\n",
    "all_data_scaled.to_csv(args.root_path + file_name_scaled, index=False)\n",
    "print(\"数据保存完毕。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子以确保结果可重现\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "\n",
    "# 获取列数\n",
    "num_columns = all_data_raw.shape[1]\n",
    "# args.des = NUM\n",
    "args.enc_in = num_columns - 1\n",
    "args.dec_in = num_columns - 1\n",
    "args.c_out = num_columns - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查并设置 GPU\n",
    "args.use_gpu = torch.cuda.is_available() and args.use_gpu\n",
    "if args.use_gpu:\n",
    "    print(\"使用 GPU.\")\n",
    "    total_cuda_devices = torch.cuda.device_count()  # 获取系统中可用的 GPU 总数\n",
    "    print(f\"系统中总共有 {total_cuda_devices} 个 CUDA 设备可用。\")\n",
    "    if args.use_multi_gpu:\n",
    "        args.devices = args.devices.replace(' ', '')\n",
    "        device_ids = args.devices.split(',')\n",
    "        args.device_ids = [int(id_) for id_ in device_ids]\n",
    "        args.gpu = args.device_ids[0]\n",
    "        \n",
    "        # 打印多 GPU 使用情况\n",
    "        print(f\"使用多个GPU: {args.device_ids}\")\n",
    "        device = torch.device(f\"cuda:{args.gpu}\" if args.use_gpu else \"cpu\")\n",
    "        print(f\"Primary GPU (cuda:{args.gpu}) is in use.\")\n",
    "    else:\n",
    "        args.gpu = 0\n",
    "        device = torch.device(\"cuda\" if args.use_gpu else \"cpu\")\n",
    "        print(\"使用单个 GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"使用 CPU.\")\n",
    "\n",
    "# 选择合适的实验类\n",
    "if args.task_name == 'long_term_forecast':\n",
    "    Exp = Exp_Long_Term_Forecast\n",
    "elif args.task_name == 'short_term_forecast':\n",
    "    Exp = Exp_Short_Term_Forecast\n",
    "elif args.task_name == 'imputation':\n",
    "    Exp = Exp_Imputation\n",
    "elif args.task_name == 'anomaly_detection':\n",
    "    Exp = Exp_Anomaly_Detection\n",
    "elif args.task_name == 'classification':\n",
    "    Exp = Exp_Classification\n",
    "else:\n",
    "    Exp = Exp_Long_Term_Forecast  # 默认情况\n",
    "\n",
    "# 进行训练和测试\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        # 实验记录设置\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "            args.task_name,\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            args.features,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            args.d_model,\n",
    "            args.n_heads,\n",
    "            args.e_layers,\n",
    "            args.d_layers,\n",
    "            args.d_ff,\n",
    "            args.factor,\n",
    "            args.embed,\n",
    "            args.distil,\n",
    "            args.des, ii)\n",
    "\n",
    "        exp = Exp(args)  # 设置实验\n",
    "        print('>>>>>>>开始训练 : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "        exp.train(setting)\n",
    "\n",
    "        print('>>>>>>>测试 : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting)\n",
    "        if args.use_gpu:\n",
    "            torch.cuda.empty_cache()\n",
    "else:\n",
    "    ii = 0\n",
    "    setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "        args.task_name,\n",
    "        args.model_id,\n",
    "        args.model,\n",
    "        args.data,\n",
    "        args.features,\n",
    "        args.seq_len,\n",
    "        args.label_len,\n",
    "        args.pred_len,\n",
    "        args.d_model,\n",
    "        args.n_heads,\n",
    "        args.e_layers,\n",
    "        args.d_layers,\n",
    "        args.d_ff,\n",
    "        args.factor,\n",
    "        args.embed,\n",
    "        args.distil,\n",
    "        args.des, ii)\n",
    "\n",
    "    exp = Exp(args)  # 设置实验\n",
    "    print('>>>>>>>测试 : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting, test=1)\n",
    "    if args.use_gpu:\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./runs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
