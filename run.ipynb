{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sktime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexp_long_term_forecasting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Exp_Long_Term_Forecast\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexp_imputation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Exp_Imputation\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexp_short_term_forecasting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Exp_Short_Term_Forecast\n",
      "File \u001b[1;32md:\\pytorch\\Time-Series-Library\\exp\\exp_long_term_forecasting.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_provider\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_factory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_provider\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexp_basic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Exp_Basic\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, adjust_learning_rate, visual\n",
      "File \u001b[1;32md:\\pytorch\\Time-Series-Library\\data_provider\\data_factory.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_provider\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom, Dataset_M4, PSMSegLoader, \\\n\u001b[0;32m      2\u001b[0m     MSLSegLoader, SMAPSegLoader, SMDSegLoader, SWATSegLoader, UEAloader\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_provider\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muea\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collate_fn\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "File \u001b[1;32md:\\pytorch\\Time-Series-Library\\data_provider\\data_loader.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_provider\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mm4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m M4Dataset, M4Meta\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_provider\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muea\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m subsample, interpolate_missing, Normalizer\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_from_tsfile_to_dataframe\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     15\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sktime'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
    "from exp.exp_imputation import Exp_Imputation\n",
    "from exp.exp_short_term_forecasting import Exp_Short_Term_Forecast\n",
    "from exp.exp_anomaly_detection import Exp_Anomaly_Detection\n",
    "from exp.exp_classification import Exp_Classification\n",
    "from data_provider.data_creat import *\n",
    "import akshare as ak\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    '''基本配置'''\n",
    "    # 选项：[long_term_forecast, short_term_forecast, imputation, classification, anomaly_detection]')\n",
    "    task_name = 'long_term_forecast'\n",
    "    is_training = 1\n",
    "    model_id = 'Stock_96_96'\n",
    "    # 模型名称，选项：[Autoformer, Transformer, TimesNet]\n",
    "    model = 'TimesNet'\n",
    "    \n",
    "    '''股票数据获取'''\n",
    "    fuquan = 'hfq'# 设置复权方式,adjust=空选择的不复权，qfq是前复权，应该用hfq后复权来进行量化分析\n",
    "    period = 'daily' # 拉取时间周期{'daily', 'weekly', 'monthly'}\n",
    "    start_date = '20151201'  # 下载数据的开始日期,0就是公司上市时间\n",
    "    end_date = '-1'  # 下载数据的结束日期,如果0则到最后一天,如果-1是昨天.\n",
    "    final_data_feat =  ['index', 'Volume','Tom_Chg'] # 删除不需要列的标签\n",
    "    label_n = 7 # 预测未来连续多少天的收益率\n",
    "    zhangfu = 0.03  # 预测涨幅大于等于3%的为1，小于3%的为0\n",
    "    label_ch = False  # 如果是True ，预测n天以后上涨大于变量zhangfu为1，小于为0\n",
    "    \n",
    "    \n",
    "    '''数据加载'''\n",
    "    # 数据集类型,选项：[ETTh1,ETTh2,ETTm1,ETTm2,custom,m4,PSM,MSL,SMAP,SMD,SWAT,UEA]\n",
    "    data = 'custom'\n",
    "    root_path = './dataset/Stock/'\n",
    "    data_path = 'Stock.csv'\n",
    "    # 预测任务 M:多变量预测多变量, S:单变量预测单变量, MS:多变量预测单变量\n",
    "    features = 'MS'\n",
    "    # 目标列名，S或MS任务中的目标特征\n",
    "    target = 'OT'\n",
    "    # 时间采集粒度，选项：[s:秒, t:分钟, h:小时, d:天, b:工作日, w:周, m:月]\n",
    "    freq = 'd'\n",
    "    # 模型检查点的位置\n",
    "    checkpoints = './checkpoints/'\n",
    "\n",
    "    '''预测任务'''\n",
    "    # 输入序列长度\n",
    "    seq_len = 96\n",
    "    # 开始标记长度\n",
    "    label_len = 48\n",
    "    # 预测序列长度\n",
    "    pred_len = 1\n",
    "    # 季节模式（针对M4数据集）\n",
    "    seasonal_patterns = 'Monthly'\n",
    "    inverse = False    # 反转输出数据\n",
    "\n",
    "    '''插补任务'''\n",
    "    # 插补任务中数据丢失率\n",
    "    mask_rate = 0.25\n",
    "\n",
    "    '''异常检测任务'''\n",
    "    # 异常检测中异常点占比\n",
    "    anomaly_ratio = 0.25\n",
    "\n",
    "    '''模型定义'''\n",
    "    # TimesBlock 中傅里叶变换,频率排名前k个周期\n",
    "    top_k = 5\n",
    "    # Inception 中卷积核个数\n",
    "    num_kernels = 6\n",
    "    # encoder 输入特征数\n",
    "    enc_in = 14\n",
    "    # decoder 输入特征数\n",
    "    dec_in = 14\n",
    "    # 输出通道数\n",
    "    c_out = 14\n",
    "    # 线性层隐含神经元个数\n",
    "    d_model = 32\n",
    "    # FFN 层隐含神经元个数\n",
    "    d_ff = 32\n",
    "    # 多头注意力机制\n",
    "    n_heads = 8\n",
    "    # encoder 层数\n",
    "    e_layers = 2\n",
    "    # decoder 层数\n",
    "    d_layers = 1\n",
    "    # 滑动窗口长度\n",
    "    moving_avg = 25\n",
    "    # 对 Q 进行采样，对 Q 采样的因子数\n",
    "    factor = 3\n",
    "    # 是否下采样操作 pooling\n",
    "    distil = True\n",
    "    # dropout 率\n",
    "    dropout = 0.1\n",
    "    # 时间特征嵌入方式,选项：[timeF, fixed, learned]\n",
    "    embed = 'timeF'\n",
    "    # 激活函数类型\n",
    "    activation = 'gelu'\n",
    "    # 是否输出 attention\n",
    "    output_attention = False\n",
    "\n",
    "    '''优化'''\n",
    "    # 并行核心数\n",
    "    num_workers = 10\n",
    "    # 实验轮数\n",
    "    itr = 1\n",
    "    # 训练迭代次数\n",
    "    train_epochs = 10\n",
    "    # batch size 大小\n",
    "    batch_size = 32\n",
    "    # early stopping 机制容忍次数\n",
    "    patience = 3\n",
    "    # 学习率\n",
    "    learning_rate = 0.0001\n",
    "    # 实验描述\n",
    "    des = 'test'\n",
    "    # 损失函数\n",
    "    loss = 'MSE'\n",
    "    # 学习率下降策略\n",
    "    lradj = 'type1'\n",
    "    # 使用混合精度训练\n",
    "    use_amp = False\n",
    "\n",
    "    '''GPU'''\n",
    "    # 使用 gpu\n",
    "    use_gpu = False\n",
    "    gpu = 0\n",
    "    # 使用多个 gpus\n",
    "    use_multi_gpu = False\n",
    "    # 多 gpu 的设备 id\n",
    "    devices = '0,1,2,3'\n",
    "\n",
    "    '''去平稳化投影仪参数'''\n",
    "    # 投影仪的隐藏层维度（列表）\n",
    "    p_hidden_dims = [128, 128]\n",
    "    # 投影仪中的隐藏层数\n",
    "    p_hidden_layers = 2\n",
    "\n",
    "\n",
    "# 创建参数对象\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取数据时间为： 20151201 - 20231214\n",
      "原始数据形状： (1957, 9)\n",
      "添加数据以后形状： (1957, 15)\n",
      "添加label以后数据形状: (1957, 17)\n",
      "删除指定行、列后数据形状:  (1925, 15)\n"
     ]
    }
   ],
   "source": [
    "stock_list = ['601857'] # 测试用\n",
    "for i in stock_list:\n",
    "    NUM = i\n",
    "    # 下载原始数据\n",
    "    raw_data = download_data(NUM, args)\n",
    "    # 拼接数据，添加各种参数\n",
    "    ad_data = add_data(raw_data.copy(), args)\n",
    "    # 添加预测标签\n",
    "    ot_data = add_label(ad_data.copy(), args)\n",
    "    # 删除无效数据\n",
    "    su_data = sub_data(ot_data.copy(), args)\n",
    "    args.des = NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据到 CSV 文件\n",
    "su_data.to_csv(args.root_path + args.data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子以确保结果可重现\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CPU\n",
      ">>>>>>>开始训练 : long_term_forecast_Stock_96_96_TimesNet_custom_ftMS_sl96_ll48_pl1_dm32_nh8_el2_dl1_df32_fc3_ebtimeF_dtTrue_601857_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 1251\n",
      "val 193\n",
      "test 385\n",
      "Epoch: 1 cost time: 58.26604437828064\n",
      "Epoch: 1, Steps: 39 | Train Loss: 1.2268151 Vali Loss: 3.0360119 Test Loss: 1.6772472\n",
      "Validation loss decreased (inf --> 3.036012).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 55.617011070251465\n",
      "Epoch: 2, Steps: 39 | Train Loss: 0.9422728 Vali Loss: 3.0409286 Test Loss: 1.5702196\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n"
     ]
    }
   ],
   "source": [
    "# 检查并设置 GPU\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ', '')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "\n",
    "# 选择合适的实验类\n",
    "if args.task_name == 'long_term_forecast':\n",
    "    Exp = Exp_Long_Term_Forecast\n",
    "elif args.task_name == 'short_term_forecast':\n",
    "    Exp = Exp_Short_Term_Forecast\n",
    "elif args.task_name == 'imputation':\n",
    "    Exp = Exp_Imputation\n",
    "elif args.task_name == 'anomaly_detection':\n",
    "    Exp = Exp_Anomaly_Detection\n",
    "elif args.task_name == 'classification':\n",
    "    Exp = Exp_Classification\n",
    "else:\n",
    "    Exp = Exp_Long_Term_Forecast  # 默认情况\n",
    "\n",
    "# 进行训练和测试\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        # 实验记录设置\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "            args.task_name,\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            args.features,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            args.d_model,\n",
    "            args.n_heads,\n",
    "            args.e_layers,\n",
    "            args.d_layers,\n",
    "            args.d_ff,\n",
    "            args.factor,\n",
    "            args.embed,\n",
    "            args.distil,\n",
    "            args.des, ii)\n",
    "\n",
    "        exp = Exp(args)  # 设置实验\n",
    "        print('>>>>>>>开始训练 : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "        exp.train(setting)\n",
    "\n",
    "        print('>>>>>>>测试 : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting)\n",
    "        if args.use_gpu:\n",
    "            torch.cuda.empty_cache()\n",
    "else:\n",
    "    ii = 0\n",
    "    setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "        args.task_name,\n",
    "        args.model_id,\n",
    "        args.model,\n",
    "        args.data,\n",
    "        args.features,\n",
    "        args.seq_len,\n",
    "        args.label_len,\n",
    "        args.pred_len,\n",
    "        args.d_model,\n",
    "        args.n_heads,\n",
    "        args.e_layers,\n",
    "        args.d_layers,\n",
    "        args.d_ff,\n",
    "        args.factor,\n",
    "        args.embed,\n",
    "        args.distil,\n",
    "        args.des, ii)\n",
    "\n",
    "    exp = Exp(args)  # 设置实验\n",
    "    print('>>>>>>>测试 : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting, test=1)\n",
    "    if args.use_gpu:\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./runs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
