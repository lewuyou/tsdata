{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive # 挂载谷歌云盘\n",
    "# drive.mount('/content/drive')\n",
    "# !nvidia-smi # 显示显卡信息\n",
    "# ''' 符号%代表一直生效，！代表执行完立马结束，不会生效，所以进入目录用% '''\n",
    "# %cd /content/drive/MyDrive/timeSerise\n",
    "# ''' 支持的 常用命令1.ls  2.wget  3.gdoint(int(int(int(w))))n  4.mkdir  5.pwd '''\n",
    "# !ls\n",
    "# !pip install patool\n",
    "# !pip install sktime\n",
    "# !pip install reformer_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
    "# from exp.exp_imputation import Exp_Imputation\n",
    "# from exp.exp_short_term_forecasting import Exp_Short_Term_Forecast\n",
    "# from exp.exp_anomaly_detection import Exp_Anomaly_Detection\n",
    "# from exp.exp_classification import Exp_Classification\n",
    "# from data_provider.data_creat import *\n",
    "# import akshare as ak\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    '''基本配置'''\n",
    "    # 选项：[long_term_forecast, short_term_forecast, imputation, classification, anomaly_detection]')\n",
    "    task_name = 'long_term_forecast'\n",
    "    is_training = 0\n",
    "    model_id = 'Stock_test'\n",
    "    # 模型名称，选项：[Autoformer, Transformer, TimesNet]\n",
    "    model = 'TimesNet'\n",
    "    \n",
    "    '''数据加载'''\n",
    "    # 数据集类型,选项：[ETTh1,ETTh2,ETTm1,ETTm2,custom,m4,PSM,MSL,SMAP,SMD,SWAT,UEA]\n",
    "    data = 'custom'\n",
    "    root_path = './dataset/Stock/'\n",
    "    data_path = 'all_data_scaled.csv'\n",
    "    # 预测任务 M:多变量预测多变量, S:单变量预测单变量, MS:多变量预测单变量\n",
    "    features = 'MS'\n",
    "    # 目标列名，S或MS任务中的目标特征\n",
    "    target = 'OT'\n",
    "    # 时间采集粒度，选项：[s:秒, t:分钟, h:小时, d:天, b:工作日, w:周, m:月]\n",
    "    freq = 'd'\n",
    "    # 模型检查点的位置\n",
    "    checkpoints = './checkpoints/'\n",
    "\n",
    "    '''预测任务'''\n",
    "    # 输入序列长度,这是用于模型训练的输入序列的长度\n",
    "    seq_len = 60\n",
    "    # 开始标记长度,这是模型输出目标中有标签数据的长度，类似于滑动窗口的长度\n",
    "    label_len = 20\n",
    "    # 预测序列长度\n",
    "    pred_len = 1\n",
    "    # 季节模式（针对M4数据集）\n",
    "    seasonal_patterns = 'Monthly'\n",
    "    inverse = False    # 反转输出数据\n",
    "\n",
    "    '''插补任务'''\n",
    "    # 插补任务中数据丢失率\n",
    "    mask_rate = 0.25\n",
    "\n",
    "    '''异常检测任务'''\n",
    "    # 异常检测中异常点占比\n",
    "    anomaly_ratio = 0.25\n",
    "\n",
    "    '''模型定义'''\n",
    "    # TimesBlock 中傅里叶变换,频率排名前k个周期\n",
    "    top_k = 5\n",
    "    # Inception 中卷积核个数\n",
    "    num_kernels = 6\n",
    "    # encoder 输入特征数\n",
    "    enc_in = 38\n",
    "    # decoder 输入特征数\n",
    "    dec_in = 38\n",
    "    # 输出通道数\n",
    "    c_out = 38\n",
    "    # 线性层隐含神经元个数\n",
    "    d_model = 32\n",
    "    # FFN 层隐含神经元个数\n",
    "    d_ff = 32\n",
    "    # 多头注意力机制\n",
    "    n_heads = 8\n",
    "    # encoder 层数\n",
    "    e_layers = 2\n",
    "    # decoder 层数\n",
    "    d_layers = 1\n",
    "    # 滑动窗口长度\n",
    "    moving_avg = 20\n",
    "    # 对 Q 进行采样，对 Q 采样的因子数\n",
    "    factor = 3\n",
    "    # 是否下采样操作 pooling\n",
    "    distil = True\n",
    "    # dropout 率\n",
    "    dropout = 0.1\n",
    "    # 时间特征嵌入方式,选项：[timeF, fixed, learned]\n",
    "    embed = 'timeF'\n",
    "    # 激活函数类型\n",
    "    activation = 'gelu'\n",
    "    # 是否输出 attention\n",
    "    output_attention = False\n",
    "\n",
    "    '''优化'''\n",
    "    # 并行核心数\n",
    "    num_workers = 10\n",
    "    # 实验轮数\n",
    "    itr = 1\n",
    "    # 训练迭代次数\n",
    "    train_epochs = 500\n",
    "    # batch size 大小\n",
    "    batch_size = 256\n",
    "    # early stopping 机制容忍次数\n",
    "    patience = 53\n",
    "    # 学习率\n",
    "    learning_rate = 0.0001\n",
    "    # 实验描述\n",
    "    des = 'stock'\n",
    "    # 损失函数\n",
    "    loss = 'MSE'\n",
    "    # 学习率下降策略\n",
    "    lradj = 'type1'\n",
    "    # 使用混合精度训练\n",
    "    use_amp = False\n",
    "\n",
    "    '''GPU'''\n",
    "    # 使用 gpu\n",
    "    use_gpu = True\n",
    "    gpu = 0\n",
    "    # 使用多个 gpus\n",
    "    use_multi_gpu = False\n",
    "    # 多 gpu 的设备 id\n",
    "    devices = '0,1,2,3'\n",
    "\n",
    "    '''去平稳化投影仪参数'''\n",
    "    # 投影仪的隐藏层维度（列表）\n",
    "    p_hidden_dims = [128, 128]\n",
    "    # 投影仪中的隐藏层数\n",
    "    p_hidden_layers = 2\n",
    "\n",
    "\n",
    "# 创建参数对象\n",
    "args = Args()\n",
    "\n",
    "# 设置随机种子以确保结果可重现\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "\n",
    "# 获取列数\n",
    "num_columns = 33\n",
    "# args.des = NUM\n",
    "args.enc_in = num_columns - 1\n",
    "args.dec_in = num_columns - 1\n",
    "args.c_out = num_columns - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用 GPU.\n",
      "系统中总共有 1 个 CUDA 设备可用。\n",
      "使用单个 GPU.\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>测试 : long_term_forecast_Stock_test_TimesNet_custom_ftMS_sl60_ll20_pl1_dm32_nh8_el2_dl1_df32_fc3_ebtimeF_dtTrue_stock_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset/Stock/all_data_scaled.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 93\u001b[0m\n\u001b[0;32m     91\u001b[0m exp \u001b[38;5;241m=\u001b[39m Exp(args)  \u001b[38;5;66;03m# 设置实验\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>测试 : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(setting))\n\u001b[1;32m---> 93\u001b[0m exp\u001b[38;5;241m.\u001b[39mtest(setting, test\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39muse_gpu:\n\u001b[0;32m     95\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[1;32md:\\pytorch\\Time-Series-Library\\exp\\exp_long_term_forecasting.py:210\u001b[0m, in \u001b[0;36mExp_Long_Term_Forecast.test\u001b[1;34m(self, setting, test)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest\u001b[39m(\u001b[38;5;28mself\u001b[39m, setting, test\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m--> 210\u001b[0m     test_data, test_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data(flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m test:\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\pytorch\\Time-Series-Library\\exp\\exp_long_term_forecasting.py:30\u001b[0m, in \u001b[0;36mExp_Long_Term_Forecast._get_data\u001b[1;34m(self, flag)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, flag):\n\u001b[1;32m---> 30\u001b[0m     data_set, data_loader \u001b[38;5;241m=\u001b[39m data_provider(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, flag)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_set, data_loader\n",
      "File \u001b[1;32md:\\pytorch\\Time-Series-Library\\data_provider\\data_factory.py:74\u001b[0m, in \u001b[0;36mdata_provider\u001b[1;34m(args, flag)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm4\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     73\u001b[0m     drop_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m data_set \u001b[38;5;241m=\u001b[39m Data(\n\u001b[0;32m     75\u001b[0m     root_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mroot_path,\n\u001b[0;32m     76\u001b[0m     data_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdata_path,\n\u001b[0;32m     77\u001b[0m     flag\u001b[38;5;241m=\u001b[39mflag,\n\u001b[0;32m     78\u001b[0m     size\u001b[38;5;241m=\u001b[39m[args\u001b[38;5;241m.\u001b[39mseq_len, args\u001b[38;5;241m.\u001b[39mlabel_len, args\u001b[38;5;241m.\u001b[39mpred_len],\n\u001b[0;32m     79\u001b[0m     features\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mfeatures,\n\u001b[0;32m     80\u001b[0m     target\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mtarget,\n\u001b[0;32m     81\u001b[0m     timeenc\u001b[38;5;241m=\u001b[39mtimeenc,\n\u001b[0;32m     82\u001b[0m     freq\u001b[38;5;241m=\u001b[39mfreq,\n\u001b[0;32m     83\u001b[0m     seasonal_patterns\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mseasonal_patterns\n\u001b[0;32m     84\u001b[0m )\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(flag, \u001b[38;5;28mlen\u001b[39m(data_set))\n\u001b[0;32m     86\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m     87\u001b[0m     data_set,\n\u001b[0;32m     88\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     89\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle_flag,\n\u001b[0;32m     90\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_workers,\n\u001b[0;32m     91\u001b[0m     drop_last\u001b[38;5;241m=\u001b[39mdrop_last)\n",
      "File \u001b[1;32md:\\pytorch\\Time-Series-Library\\data_provider\\data_loader.py:235\u001b[0m, in \u001b[0;36mDataset_Custom.__init__\u001b[1;34m(self, root_path, flag, size, features, data_path, target, scale, timeenc, freq, seasonal_patterns)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_path \u001b[38;5;241m=\u001b[39m root_path\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path \u001b[38;5;241m=\u001b[39m data_path\n\u001b[1;32m--> 235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__read_data__()\n",
      "File \u001b[1;32md:\\pytorch\\Time-Series-Library\\data_provider\\data_loader.py:241\u001b[0m, in \u001b[0;36mDataset_Custom.__read_data__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# 读取数据\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m df_raw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_path,\n\u001b[0;32m    242\u001b[0m                                   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path))\n\u001b[0;32m    244\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03mdf_raw.columns: ['date', ...(other features), target feature]\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    247\u001b[0m cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(df_raw\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\torch\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\torch\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\torch\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\torch\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\torch\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/Stock/all_data_scaled.csv'"
     ]
    }
   ],
   "source": [
    "# 检查并设置 GPU\n",
    "args.use_gpu = torch.cuda.is_available() and args.use_gpu\n",
    "if args.use_gpu:\n",
    "    print(\"使用 GPU.\")\n",
    "    total_cuda_devices = torch.cuda.device_count()  # 获取系统中可用的 GPU 总数\n",
    "    print(f\"系统中总共有 {total_cuda_devices} 个 CUDA 设备可用。\")\n",
    "    if args.use_multi_gpu:\n",
    "        args.devices = args.devices.replace(' ', '')\n",
    "        device_ids = args.devices.split(',')\n",
    "        args.device_ids = [int(id_) for id_ in device_ids]\n",
    "        args.gpu = args.device_ids[0]\n",
    "        \n",
    "        # 打印多 GPU 使用情况\n",
    "        print(f\"使用多个GPU: {args.device_ids}\")\n",
    "        device = torch.device(f\"cuda:{args.gpu}\" if args.use_gpu else \"cpu\")\n",
    "        print(f\"Primary GPU (cuda:{args.gpu}) is in use.\")\n",
    "    else:\n",
    "        args.gpu = 0\n",
    "        device = torch.device(\"cuda\" if args.use_gpu else \"cpu\")\n",
    "        print(\"使用单个 GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"使用 CPU.\")\n",
    "\n",
    "# 选择合适的实验类\n",
    "if args.task_name == 'long_term_forecast':\n",
    "    Exp = Exp_Long_Term_Forecast\n",
    "# elif args.task_name == 'short_term_forecast':\n",
    "#     Exp = Exp_Short_Term_Forecast\n",
    "# elif args.task_name == 'imputation':\n",
    "#     Exp = Exp_Imputation\n",
    "# elif args.task_name == 'anomaly_detection':\n",
    "#     Exp = Exp_Anomaly_Detection\n",
    "# elif args.task_name == 'classification':\n",
    "#     Exp = Exp_Classification\n",
    "else:\n",
    "    Exp = Exp_Long_Term_Forecast  # 默认情况\n",
    "\n",
    "# 进行训练和测试\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        # 实验记录设置\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "            args.task_name,\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            args.features,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            args.d_model,\n",
    "            args.n_heads,\n",
    "            args.e_layers,\n",
    "            args.d_layers,\n",
    "            args.d_ff,\n",
    "            args.factor,\n",
    "            args.embed,\n",
    "            args.distil,\n",
    "            args.des, ii)\n",
    "\n",
    "        exp = Exp(args)  # 设置实验\n",
    "        print('>>>>>>>开始训练 : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "        exp.train(setting)\n",
    "\n",
    "        print('>>>>>>>测试 : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting)\n",
    "        if args.use_gpu:\n",
    "            torch.cuda.empty_cache()\n",
    "else:\n",
    "    ii = 0\n",
    "    setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "        args.task_name,\n",
    "        args.model_id,\n",
    "        args.model,\n",
    "        args.data,\n",
    "        args.features,\n",
    "        args.seq_len,\n",
    "        args.label_len,\n",
    "        args.pred_len,\n",
    "        args.d_model,\n",
    "        args.n_heads,\n",
    "        args.e_layers,\n",
    "        args.d_layers,\n",
    "        args.d_ff,\n",
    "        args.factor,\n",
    "        args.embed,\n",
    "        args.distil,\n",
    "        args.des, ii)\n",
    "\n",
    "    exp = Exp(args)  # 设置实验\n",
    "    print('>>>>>>>测试 : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting, test=1)\n",
    "    if args.use_gpu:\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./tensorboard_logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
