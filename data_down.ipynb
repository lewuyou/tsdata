{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive # 挂载谷歌云盘\n",
    "# drive.mount('/content/drive')\n",
    "# !nvidia-smi # 显示显卡信息\n",
    "# ''' 符号%代表一直生效，！代表执行完立马结束，不会生效，所以进入目录用% '''\n",
    "# %cd /content/drive/MyDrive/timeSerise\n",
    "# ''' 支持的 常用命令1.ls  2.wget  3.gdoint(int(int(int(w))))n  4.mkdir  5.pwd '''\n",
    "# !ls\n",
    "# !pip install pyti\n",
    "# !pip install akshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.data_creat import *\n",
    "import akshare as ak\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    '''股票数据获取'''\n",
    "    fuquan = 'hfq'# 设置复权方式,adjust=空选择的不复权，qfq是前复权，应该用hfq后复权来进行量化分析\n",
    "    period = 'daily' # 拉取时间周期{'daily', 'weekly', 'monthly'}\n",
    "    start_date = '20151201'  # 20151201   20221021  下载数据的开始日期,1就是公司上市时间\n",
    "    end_date = '20231230'  # '20231220' 下载数据的结束日期,如果1则到最后一天,如果-1是昨天.\n",
    "    label_n = 5 # 预测未来连续多少天的收益率\n",
    "    root_path = './dataset/Stock/'\n",
    "    \n",
    "    # 预测目标y是否替换成1或者0\n",
    "    zhangfu = 0.10  # 预测涨幅大于等于3%的为1，小于3%的为0\n",
    "    label_ch = False  # 如果是True ，预测n天以后上涨大于变量zhangfu为1，小于为0\n",
    "\n",
    "    # 是否合并全部股票数据\n",
    "    all = True # 是否合并全部股票数据\n",
    "    data_addzero = 60 # 当all = True时，用于训练的数据集分割，前面补0的长度\n",
    "    \n",
    "    # 数据修剪\n",
    "    start = 103 # 删除前24行（start=25），因为macd算不出来\n",
    "    end = 0 # (end = label_n if all else 0)删除最后部分需要预测天数label_n的数据，算出来是0.如果单只股票预测，那么不需要删除\n",
    "    final_data_feat =  ['index', 'Volume','Tom_Chg'] # 删除不需要列的标签\n",
    "\n",
    "# 创建参数对象\n",
    "args = Args()\n",
    "\n",
    "# 创建股票数据列表\n",
    "stock_down = ak.stock_cy_a_spot_em() # 创业板实时数据\n",
    "stock_list = stock_down[~stock_down['名称'].str.contains(\"退|ST\") & (stock_down['流通市值'] <= 1e11) & (stock_down['总市值'] >= 45e8)] # 去除退市和ST股票\n",
    "file_name_cy = 'Stock_list_cy.csv'# 保存数据，编码格式为utf-8\n",
    "stock_list.to_csv(args.root_path + file_name_cy,index=False,encoding='utf-8-sig')\n",
    "\n",
    "# 读取股票列表\n",
    "stock_list = pd.read_csv(args.root_path + file_name_cy) # 读取股票列表\n",
    "# 将股票代码的数字转换为字符串列表\n",
    "stock_list = [str(code) for code in stock_list['代码'].tolist()]\n",
    "\n",
    "stock_list = ['000158'] # 自定义股票列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取数据时间为： 20151201 - 20240104\n",
      "原始数据形状： (1962, 9)\n",
      "添加数据以后形状： (1962, 33)\n",
      "删除指定行、列后数据形状:  (1859, 32)\n",
      "股票代码 000158 的数据保存到 scaled_stock_cy_000158.csv ，形状: (1859, 32)\n",
      "处理进度: 1/1 (100.00%)\n",
      "单独数据保存完毕。\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "all_data_raw = pd.DataFrame()  # 初始化一个空的 DataFrame 用于存储原始数据\n",
    "all_data_scaled = pd.DataFrame()  # 初始化一个空的 DataFrame 用于存储标准化后的数据\n",
    "processed_count = 0  # 初始化计数器\n",
    "total_count = len(stock_list)  # 获取总股票数量\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in stock_list[:]:\n",
    "    NUM = i\n",
    "    try:\n",
    "        # 下载原始数据\n",
    "        raw_data = download_data(NUM, args)\n",
    "        # 更新已处理股票数量计数器\n",
    "        processed_count += 1\n",
    "        # 检查数据长度，如果小于300则跳过此次循环\n",
    "        if raw_data.shape[0] < 280:\n",
    "            print(f\"股票代码 {NUM} 的数据长度小于300,跳过此次循环。\")\n",
    "            continue\n",
    "        \n",
    "        # 拼接数据，添加各种参数\n",
    "        ad_data = add_data(raw_data, args)\n",
    "        # 添加预测标签\n",
    "        # ad_data = add_label(ad_data, args)\n",
    "        # 删除无效数据\n",
    "        final_data_raw = sub_data(ad_data.copy(), args)\n",
    "        final_data_scaled = final_data_raw.copy()\n",
    "        \n",
    "        # 未处理数据的前20行替换为0\n",
    "        if args.data_addzero and not all_data_raw.empty:\n",
    "            final_data_raw = add_zeros_to_data(final_data_raw, num_rows=args.data_addzero)\n",
    "\n",
    "        # 标准化处理\n",
    "        non_time_columns = final_data_scaled.columns[1:-1]  # 假设时间列是第一列\n",
    "        final_data_scaled[non_time_columns] = scaler.fit_transform(final_data_scaled[non_time_columns])\n",
    "\n",
    "        # 标准化处理的数据的前20行替换为0\n",
    "        if args.data_addzero and not all_data_scaled.empty:\n",
    "            final_data_scaled = add_zeros_to_data(final_data_scaled, num_rows=args.data_addzero)\n",
    "        \n",
    "        # 如果 all 为 False, 则为每个股票单独保存数据\n",
    "        if not args.all:\n",
    "            file_name_raw_individual = f\"raw_stock_cy_{NUM}.csv\"\n",
    "            file_name_scaled_individual = f\"scaled_stock_cy_{NUM}.csv\"\n",
    "            final_data_raw.to_csv(args.root_path + file_name_raw_individual, index=False)\n",
    "            final_data_scaled.to_csv(args.root_path + file_name_scaled_individual, index=False)\n",
    "            print(f\"股票代码 {NUM} 的数据保存到 {file_name_scaled_individual} ，形状: {final_data_raw.shape}\")\n",
    "        else:\n",
    "            # 拼接未处理的数据\n",
    "            all_data_raw = pd.concat([all_data_raw, final_data_raw], ignore_index=True)\n",
    "            # 拼接经过标准化的数据\n",
    "            all_data_scaled = pd.concat([all_data_scaled, final_data_scaled], ignore_index=True)\n",
    "            print(f\"当前all_data的形状: {all_data_scaled.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"处理股票代码 {NUM} 时出现错误: {e}\")\n",
    "        continue\n",
    "\n",
    "    # 计算并打印处理进度\n",
    "    progress = processed_count / total_count\n",
    "    print(f\"处理进度: {processed_count}/{total_count} ({progress:.2%})\")\n",
    "\n",
    "# 如果 all 为 True, 则保存合并后的数据\n",
    "if args.all:\n",
    "    time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    file_name_raw = \"stock_cy_all_raw.csv\"\n",
    "    file_name_scaled = \"stock_cy_all_scaled.csv\"\n",
    "    all_data_raw.to_csv(args.root_path + time + file_name_raw, index=False)\n",
    "    all_data_scaled.to_csv(args.root_path + time + file_name_scaled, index=False)\n",
    "    print(\"合并数据保存完毕。\")\n",
    "else:\n",
    "    print(\"单独数据保存完毕。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
