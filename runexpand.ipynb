{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48485,"status":"ok","timestamp":1703420845644,"user":{"displayName":"wuyou le","userId":"02064837638103088801"},"user_tz":-480},"id":"G_THiylmwOSY","outputId":"b577f14a-771b-432c-a2df-95b202256f19"},"outputs":[],"source":["# from google.colab import drive # 挂载谷歌云盘\n","# drive.mount('/content/drive')\n","# !nvidia-smi # 显示显卡信息\n","# ''' 符号%代表一直生效，！代表执行完立马结束，不会生效，所以进入目录用% '''\n","# %cd /content/drive/MyDrive/timeSerise\n","# ''' 支持的 常用命令1.ls  2.wget  3.gdoint(int(int(int(w))))n  4.mkdir  5.pwd '''\n","# !ls\n","# !pip install patool\n","# !pip install sktime\n","# !pip install reformer_pytorch"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":27556,"status":"ok","timestamp":1703420873192,"user":{"displayName":"wuyou le","userId":"02064837638103088801"},"user_tz":-480},"id":"fpLAwpfLwOSd"},"outputs":[],"source":["import random\n","import numpy as np\n","import torch\n","from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast\n","# from exp.exp_imputation import Exp_Imputation\n","# from exp.exp_short_term_forecasting import Exp_Short_Term_Forecast\n","# from exp.exp_anomaly_detection import Exp_Anomaly_Detection\n","# from exp.exp_classification import Exp_Classification\n","# from data_provider.data_creat import *\n","# import akshare as ak\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1703420873192,"user":{"displayName":"wuyou le","userId":"02064837638103088801"},"user_tz":-480},"id":"mB6Cl7NswOSe"},"outputs":[{"name":"stdout","output_type":"stream","text":["使用 GPU.\n","系统中总共有 1 个 CUDA 设备可用。\n","使用单个 GPU.\n"]}],"source":["class Args:\n","    '''基本配置'''\n","    # 选项：[long_term_forecast, short_term_forecast, imputation, classification, anomaly_detection]')\n","    task_name = 'long_term_forecast'\n","    is_training = 1 # 设置为1则进行训练，设置为0则进行测试\n","    model_id = 'stock_cy'\n","    des = '20231210' # 实验描述 20231210\n","    # 模型名称，选项：[Autoformer, Transformer, TimesNet]\n","    model = 'TimesNet'\n","\n","    '''数据加载'''\n","    # 数据集类型,选项：[ETTh1,ETTh2,ETTm1,ETTm2,custom,m4,PSM,MSL,SMAP,SMD,SWAT,UEA]\n","    data = 'custom'\n","    test_path = 'raw_stock_cy_301327.csv'\n","    root_path = './dataset/Stock/'\n","    # 根据 is_training 的值设置 data_path\n","    if is_training == 1:\n","        data_path = 'stock_cy_all_raw.csv'\n","    else:\n","        data_path = test_path\n","    # 预测任务 M:多变量预测多变量, S:单变量预测单变量, MS:多变量预测单变量\n","    features = 'M'\n","    # 目标列名，S或MS任务中的目标特征\n","    target = 'Close'\n","    # 时间采集粒度，选项：[s:秒, t:分钟, h:小时, d:天, b:工作日, w:周, m:月]\n","    freq = 'd'\n","    # 模型检查点的位置\n","    checkpoints = './checkpoints/'\n","\n","    '''预测任务'''\n","    # 输入序列长度,这是用于模型训练的输入序列的长度\n","    seq_len = 60\n","    # 开始标记长度,这是模型输出目标中有标签数据的长度，类似于滑动窗口的长度\n","    label_len = 20\n","    # 预测序列长度\n","    pred_len = 20\n","    # 季节模式（针对M4数据集）\n","    seasonal_patterns = 'Monthly'\n","    inverse = False    # 反转输出数据\n","\n","    '''插补任务'''\n","    # 插补任务中数据丢失率\n","    mask_rate = 0.25\n","\n","    '''异常检测任务'''\n","    # 异常检测中异常点占比\n","    anomaly_ratio = 0.25\n","\n","    '''模型定义'''\n","    # TimesBlock 中傅里叶变换,频率排名前k个周期\n","    top_k = 5\n","    # Inception 中卷积核个数\n","    num_kernels = 6\n","    # encoder 输入特征数\n","    enc_in = 31\n","    # decoder 输入特征数\n","    dec_in = 31\n","    # 输出通道数\n","    c_out = 31\n","    # 线性层隐含神经元个数\n","    d_model = 32\n","    # FFN 层隐含神经元个数\n","    d_ff = 32\n","    # 多头注意力机制\n","    n_heads = 8\n","    # encoder 层数\n","    e_layers = 2\n","    # decoder 层数\n","    d_layers = 1\n","    # 滑动窗口长度\n","    moving_avg = 20\n","    # 对 Q 进行采样，对 Q 采样的因子数\n","    factor = 3\n","    # 是否下采样操作 pooling\n","    distil = True\n","    # dropout 率\n","    dropout = 0.1\n","    # 时间特征嵌入方式,选项：[timeF, fixed, learned]\n","    embed = 'timeF'\n","    # 激活函数类型\n","    activation = 'gelu'\n","    # 是否输出 attention\n","    output_attention = False\n","\n","    '''优化'''\n","    # 测试集的比例\n","    if is_training == 1:\n","        test_ratio = [0.1,0.1] # test测试集、valid验证集的占比\n","    else:\n","        test_ratio = [0.6,0.1]\n","\n","    # 并行核心数\n","    num_workers = 10\n","    # 实验轮数\n","    itr = 1\n","    # 训练迭代次数\n","    train_epochs = 500\n","    # batch size 大小\n","    batch_size = 256\n","    # early stopping 机制容忍次数\n","    patience = 5\n","    # 学习率\n","    learning_rate = 0.0001\n","    # 损失函数\n","    loss = 'MSE'\n","    # 学习率下降策略\n","    lradj = 'type1'\n","    # 使用混合精度训练\n","    use_amp = False\n","\n","    '''GPU'''\n","    # 使用 gpu\n","    use_gpu = True\n","    gpu = 0\n","    # 使用多个 gpus\n","    use_multi_gpu = False\n","    # 多 gpu 的设备 id\n","    devices = '0,1,2,3'\n","\n","    '''去平稳化投影仪参数'''\n","    # 投影仪的隐藏层维度（列表）\n","    p_hidden_dims = [128, 128]\n","    # 投影仪中的隐藏层数\n","    p_hidden_layers = 2\n","\n","\n","# 创建参数对象\n","args = Args()\n","\n","# 设置随机种子以确保结果可重现\n","fix_seed = 2021\n","random.seed(fix_seed)\n","torch.manual_seed(fix_seed)\n","np.random.seed(fix_seed)\n","\n","\n","# 获取列数\n","num_columns = 32\n","# args.des = NUM\n","args.enc_in = num_columns - 1\n","args.dec_in = num_columns - 1\n","args.c_out = num_columns - 1\n","\n","# 检查并设置 GPU\n","args.use_gpu = torch.cuda.is_available() and args.use_gpu\n","if args.use_gpu:\n","    print(\"使用 GPU.\")\n","    total_cuda_devices = torch.cuda.device_count()  # 获取系统中可用的 GPU 总数\n","    print(f\"系统中总共有 {total_cuda_devices} 个 CUDA 设备可用。\")\n","    if args.use_multi_gpu:\n","        args.devices = args.devices.replace(' ', '')\n","        device_ids = args.devices.split(',')\n","        args.device_ids = [int(id_) for id_ in device_ids]\n","        args.gpu = args.device_ids[0]\n","\n","        # 打印多 GPU 使用情况\n","        print(f\"使用多个GPU: {args.device_ids}\")\n","        device = torch.device(f\"cuda:{args.gpu}\" if args.use_gpu else \"cpu\")\n","        print(f\"Primary GPU (cuda:{args.gpu}) is in use.\")\n","    else:\n","        args.gpu = 0\n","        device = torch.device(\"cuda\" if args.use_gpu else \"cpu\")\n","        print(\"使用单个 GPU.\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"使用 CPU.\")\n","\n","\n","# 选择合适的实验类\n","if args.task_name == 'long_term_forecast':\n","    Exp = Exp_Long_Term_Forecast\n","# elif args.task_name == 'short_term_forecast':\n","#     Exp = Exp_Short_Term_Forecast\n","# elif args.task_name == 'imputation':\n","#     Exp = Exp_Imputation\n","# elif args.task_name == 'anomaly_detection':\n","#     Exp = Exp_Anomaly_Detection\n","# elif args.task_name == 'classification':\n","#     Exp = Exp_Classification\n","else:\n","    Exp = Exp_Long_Term_Forecast  # 默认情况\n","    \n","    \n","ii = 0\n","setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n","            args.task_name, # 任务名称\n","            args.model_id, # 模型id\n","            args.model, # 模型名称\n","            args.data, # 数据集名称\n","            args.features, # 预测任务\n","            args.seq_len, # 输入序列长度\n","            args.label_len, # 开始标记长度\n","            args.pred_len, # 预测序列长度\n","            args.d_model, # encoder 输入特征数\n","            args.n_heads, # 多头注意力机制\n","            args.e_layers, # encoder 层数\n","            args.d_layers, # decoder 层数\n","            args.d_ff, # FFN 层隐含神经元个数\n","            args.factor, # 对 Q 采样的因子数\n","            args.embed, # 时间特征嵌入方式\n","            args.distil, # 是否下采样操作 pooling\n","            args.des,  # 实验描述\n","            ii) # 实验轮数"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import glob\n","import re\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import StandardScaler\n","from utils.timefeatures import time_features\n","from data_provider.m4 import M4Dataset, M4Meta\n","from data_provider.uea import subsample, interpolate_missing, Normalizer\n","from sktime.datasets import load_from_tsfile_to_dataframe\n","import warnings\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{},"source":["# A"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Dataset_Custom(Dataset):\n","    '''\n","    root_path: 数据集文件所在的根目录路径。\n","    flag: 数据集的类型（'train'、'test' 或 'val'），默认为 'train'。\n","    size: 一个包含三个整数的元组，分别表示序列长度、标签长度和预测长度。\n","    features: 特征类型，'S' 表示单变量(single)，默认为 'S'。\n","    data_path: 数据文件的名称，默认为 'ETTh1.csv'。\n","    target: 目标变量的名称。\n","    scale: 布尔值，指示是否对数据进行标准化处理。\n","    timeenc: 时间编码类型(0 或 1),用于处理时间特征。\n","    freq: 时间频率。\n","    seasonal_patterns: 季节性模式（如果有）。\n","    '''\n","    def __init__(self, root_path, flag='train', size=None,\n","                 features='S', data_path='ETTh1.csv',\n","                 target='OT', scale=True, timeenc=0, freq='h', test_ratio=0.2 , seasonal_patterns=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24 * 4 * 4\n","            self.label_len = 24 * 4\n","            self.pred_len = 24 * 4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train': 0, 'val': 1, 'test': 2}\n","        self.set_type = type_map[flag]\n","\n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.timeenc = timeenc\n","        self.freq = freq\n","\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.test_ratio = test_ratio\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        '''\n","        读取数据长度,区分train、test、vali三部分数据的边界\n","        '''\n","        # 数据标准化实例\n","        self.scaler = StandardScaler()\n","        # 读取数据\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        cols = list(df_raw.columns)\n","        cols.remove(self.target) # 移除目标特征\n","        cols.remove('date') # 移除日期特征\n","        df_raw = df_raw[['date'] + cols + [self.target]] # 重新排序以后的数据\n","        \n","        # 数据拆分比例\n","        num_train = int(len(df_raw) * (1-self.test_ratio[0]-self.test_ratio[1]))\n","        num_test = int(len(df_raw) * self.test_ratio[0])\n","        num_vali = len(df_raw) - num_train - num_test\n","        \n","        # 计算train、test、vali数据起始点，也就是拆分完的纵向数据长度\n","        border1s = [0, num_train - self.seq_len, len(df_raw) - num_test - self.seq_len]  # [0，train长度-60，train+valid长度-60 ]\n","        border2s = [num_train, num_train + num_vali, len(df_raw)] # [train长度，train+valid长度，原始长度]\n","        border1 = border1s[self.set_type] # set_type {'train': 0, 'val': 1, 'test': 2} 减去输入序列长度\n","        border2 = border2s[self.set_type] # set_type {'train': 0, 'val': 1, 'test': 2}\n","\n","        # 如果预测对象为多变量预测或多元预测单变量，那么取除日期外得所有列为df_data\n","        if self.features == 'M' or self.features == 'MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        # 若预测类型为S(单特征预测单特征)\n","        elif self.features == 'S':\n","            df_data = df_raw[[self.target]]\n","\n","        # 原始全部数据归一化\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]] # 训练数据\n","            self.scaler.fit(train_data.values) # 训练数据归一化\n","            data = self.scaler.transform(df_data.values) # 全部数据归一化\n","        else:\n","            data = df_data.values  # 不归一化\n","        \n","        # 处理日期格式\n","        df_stamp = df_raw[['date']][border1:border2] # {'train': 0, 'val': 1, 'test': 2}\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)# 利用pandas将数据转换为日期格式\n","        if self.timeenc == 0: # 构建时间特征\n","            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n","            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n","            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n","            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n","            data_stamp = df_stamp.drop(['date'], 1).values\n","        elif self.timeenc == 1:\n","            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq) # 时间特征构造函数，用来提取日期特征\n","            data_stamp = data_stamp.transpose(1, 0)            # 转置\n","        \n","        # 计算train、test、vali的 X和Y部分数据长度，是相等的长度 \n","        self.data_x = data[border1:border2] # {'train': 0, 'val': 1, 'test': 2}\n","        self.data_y = data[border1:border2] # {'train': 0, 'val': 1, 'test': 2}\n","        self.data_stamp = data_stamp\n","        \n","    def __getitem__(self, index):\n","        '''\n","        区分特征X在第几列  和 标签Y在第几列\n","        label_len 滑动窗口长度 20\n","        seq_len 输入序列长度 60\n","        \n","        预测的基本思想是将已知序列长度延长到 (seq_len+pred_len)，这是预测后的总长度。\n","        '''\n","        # 取得起始标签\n","        s_begin = index                                  # X 的开始位置。n\n","        s_end = s_begin + self.seq_len                   # X 的结束位置。开始标签 到 输入序列长度 的区间 n+60=n+60\n","        r_begin = s_end - self.label_len                 # Y 的开始位置。X结束位置 减去 滑动窗口长度 n+60-20=n+40  从第40个开始是第一个Y\n","        r_end = r_begin + self.label_len + self.pred_len # Y 的结束位置。Y开始位置 加上 滑动窗口长度 加上 预测长度n+40+20+1=n+61\n","\n","        # 取训练数据\n","        seq_x = self.data_x[s_begin:s_end] # 0：60\n","        seq_y = self.data_y[r_begin:r_end] # 40：61\n","        # 取训练数据对应时间特征\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        # 取有标签区间+无标签区间(预测时间步长)对应时间特征\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","\n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len - self.pred_len + 1  # 0：60  60：61  61：61\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)  # 反归一化\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# B"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import os\n","import torch\n","from models import Autoformer, Transformer, TimesNet, Nonstationary_Transformer, DLinear, FEDformer, \\\n","    Informer, LightTS, Reformer, ETSformer, Pyraformer, PatchTST, MICN, Crossformer, FiLM, iTransformer, \\\n","    Koopa\n","\n","\n","class Exp_Basic(object):\n","    def __init__(self, args):\n","        self.args = args\n","        self.model_dict = {\n","            'TimesNet': TimesNet,\n","            'Autoformer': Autoformer,\n","            'Transformer': Transformer,\n","            'Nonstationary_Transformer': Nonstationary_Transformer,\n","            'DLinear': DLinear,\n","            'FEDformer': FEDformer,\n","            'Informer': Informer,\n","            'LightTS': LightTS,\n","            'Reformer': Reformer,\n","            'ETSformer': ETSformer,\n","            'PatchTST': PatchTST,\n","            'Pyraformer': Pyraformer,\n","            'MICN': MICN,\n","            'Crossformer': Crossformer,\n","            'FiLM': FiLM,\n","            'iTransformer': iTransformer,\n","            'Koopa': Koopa,\n","        }\n","        self.device = self._acquire_device()\n","        self.model = self._build_model().to(self.device)\n","\n","    def _build_model(self):\n","        raise NotImplementedError\n","        return None\n","\n","    def _acquire_device(self):\n","        if self.args.use_gpu:\n","            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(\n","                self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n","            device = torch.device('cuda:{}'.format(self.args.gpu))\n","            print('Use GPU: cuda:{}'.format(self.args.gpu))\n","        else:\n","            device = torch.device('cpu')\n","            print('Use CPU')\n","        return device\n","\n","    def _get_data(self):\n","        pass\n","\n","    def vali(self):\n","        pass\n","\n","    def train(self):\n","        pass\n","\n","    def test(self):\n","        pass\n","    \n","    def predict(self):\n","        pass"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["class Exp_Long_Term_Forecast(Exp_Basic):\n","    def __init__(self, args):\n","        super(Exp_Long_Term_Forecast, self).__init__(args)\n","\n","    def _build_model(self):\n","        model = self.model_dict[self.args.model].Model(self.args).float()\n","\n","        if self.args.use_multi_gpu and self.args.use_gpu:\n","            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n","        return model\n","\n","    def _get_data(self, flag): # 加载数据\n","        data_set, data_loader = data_provider(self.args, flag)\n","        return data_set, data_loader\n","\n","    def _select_optimizer(self):\n","        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n","        return model_optim\n","\n","    def _select_criterion(self):\n","        criterion = nn.MSELoss()\n","        return criterion\n","\n","    def vali(self, vali_data, vali_loader, criterion):\n","        total_loss = []\n","        self.model.eval()\n","        with torch.no_grad():\n","            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n","                batch_x = batch_x.float().to(self.device)\n","                batch_y = batch_y.float()\n","\n","                batch_x_mark = batch_x_mark.float().to(self.device)\n","                batch_y_mark = batch_y_mark.float().to(self.device)\n","\n","                # decoder input\n","                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n","                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n","                # encoder - decoder\n","                if self.args.use_amp:\n","                    with torch.cuda.amp.autocast():\n","                        if self.args.output_attention:\n","                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                        else:\n","                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","                else:\n","                    if self.args.output_attention:\n","                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                    else:\n","                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","                f_dim = -1 if self.args.features == 'MS' else 0\n","                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n","                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n","\n","                pred = outputs.detach().cpu()\n","                true = batch_y.detach().cpu()\n","\n","                loss = criterion(pred, true)\n","\n","                total_loss.append(loss)\n","        total_loss = np.average(total_loss)\n","        self.model.train()\n","        return total_loss\n","\n","    def train(self, setting):\n","        # 取得训练、验证、测试数据及数据加载器\n","        writer = SummaryWriter(log_dir=os.path.join('tensorboard_logs', setting))\n","        train_data, train_loader = self._get_data(flag='train')\n","        vali_data, vali_loader = self._get_data(flag='val')\n","        test_data, test_loader = self._get_data(flag='test')\n","\n","        path = os.path.join(self.args.checkpoints, setting)\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","\n","        time_now = time.time()\n","\n","        # 取训练步数\n","        train_steps = len(train_loader)\n","        # 设置早停参数\n","        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n","\n","        # 选择优化器\n","        model_optim = self._select_optimizer()\n","        # 选择损失函数\n","        criterion = self._select_criterion()\n","\n","        # 如果多GPU并行\n","        if self.args.use_amp:\n","            scaler = torch.cuda.amp.GradScaler()\n","\n","        # 训练次数\n","        for epoch in range(self.args.train_epochs):\n","            iter_count = 0\n","            train_loss = []\n","\n","            self.model.train() # 将模型设置为训练模式.\n","            epoch_time = time.time()\n","            train_pbar = tqdm(train_loader, position=0, leave=True) # 载入进度条\n","            \n","            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_pbar):\n","                iter_count += 1\n","                # 梯度归零\n","                model_optim.zero_grad()\n","                \n","                # 取训练数据\n","                batch_x = batch_x.float().to(self.device)\n","\n","                batch_y = batch_y.float().to(self.device)\n","                batch_x_mark = batch_x_mark.float().to(self.device)\n","                batch_y_mark = batch_y_mark.float().to(self.device)\n","\n","                # decoder input\n","                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n","                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n","\n","                # encoder - decoder 并行计算\n","                if self.args.use_amp:\n","                    with torch.cuda.amp.autocast():\n","                        if self.args.output_attention:\n","                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                        else:\n","                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","\n","                        f_dim = -1 if self.args.features == 'MS' else 0\n","                        outputs = outputs[:, -self.args.pred_len:, f_dim:]\n","                        batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n","                        loss = criterion(outputs, batch_y)\n","                        train_loss.append(loss.item())\n","                else:\n","                    if self.args.output_attention:\n","                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                    else:\n","                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","\n","                    # 如果预测方式为MS，取最后1列否则取第1列\n","                    f_dim = -1 if self.args.features == 'MS' else 0\n","                    outputs = outputs[:, -self.args.pred_len:, f_dim:]\n","                    batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n","                    # 计算损失\n","                    loss = criterion(outputs, batch_y)\n","                    # 将损失放入train_loss列表中\n","                    train_loss.append(loss.item())\n","\n","                # 记录训练过程\n","                if (i + 1) % 100 == 0:\n","                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n","                    speed = (time.time() - time_now) / iter_count\n","                    left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n","                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n","                    iter_count = 0\n","                    time_now = time.time()\n","\n","                if self.args.use_amp:\n","                    scaler.scale(loss).backward()\n","                    scaler.step(model_optim)\n","                    scaler.update()\n","                else:\n","                    # 反向传播\n","                    loss.backward()\n","                    # 更新梯度\n","                    model_optim.step()\n","            # 在 tqdm 进度条上显示当前 epoch number和loss .\n","            train_pbar.set_description(f'Epoch [{epoch+1}/{self.args.train_epochs}]') # 设置进度条的前缀\n","            train_pbar.set_postfix({'loss' : loss.detach().item()}) # 设置进度条的后缀\n","\n","            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n","            train_loss = np.average(train_loss) # 计算平均损失\n","            writer.add_scalar('Loss/train_epoch', train_loss, epoch) # 将训练损失写入tensorboard\n","            print(\"正在计算验证集Loss...\")\n","            vali_loss = self.vali(vali_data, vali_loader, criterion) # 计算验证损失\n","            writer.add_scalar('Loss/val', vali_loss, epoch) # 将验证损失写入tensorboard\n","            print(\"正在计算测试集Loss...\")\n","            test_loss = self.vali(test_data, test_loader, criterion) # 计算测试损失\n","\n","            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n","                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n","            early_stopping(vali_loss, self.model, path)\n","            if early_stopping.early_stop:\n","                print(\"Early stopping\")\n","                break\n","\n","            # 更新学习率\n","            adjust_learning_rate(model_optim, epoch + 1, self.args)\n","\n","        # 保存模型\n","        best_model_path = path + '/' + 'checkpoint.pth'\n","        self.model.load_state_dict(torch.load(best_model_path))\n","        writer.close()\n","\n","        return self.model"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Use CPU\n",">>>>>>>开始训练 : long_term_forecast_stock_cy_TimesNet_custom_ftM_sl60_ll20_pl20_dm32_nh8_el2_dl1_df32_fc3_ebtimeF_dtTrue_20231210_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 1407\n","val 168\n","test_batch_size:  256\n","test 166\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/5 [00:30<?, ?it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m exp \u001b[38;5;241m=\u001b[39m Exp(args) \u001b[38;5;66;03m# 创建实验对象\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>开始训练 : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(setting))\n\u001b[1;32m----> 3\u001b[0m exp\u001b[38;5;241m.\u001b[39mtrain(setting)\n","File \u001b[1;32md:\\pytorch\\Time-Series-Library\\exp\\exp_long_term_forecasting.py:117\u001b[0m, in \u001b[0;36mExp_Long_Term_Forecast.train\u001b[1;34m(self, setting)\u001b[0m\n\u001b[0;32m    114\u001b[0m epoch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    115\u001b[0m train_pbar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# 载入进度条\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (batch_x, batch_y, batch_x_mark, batch_y_mark) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_pbar):\n\u001b[0;32m    118\u001b[0m     iter_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# 梯度归零\u001b[39;00m\n","File \u001b[1;32md:\\miniconda3\\envs\\my\\Lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[1;32md:\\miniconda3\\envs\\my\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n","File \u001b[1;32md:\\miniconda3\\envs\\my\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[38;5;28mself\u001b[39m)\n","File \u001b[1;32md:\\miniconda3\\envs\\my\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1035\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m w\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n","File \u001b[1;32md:\\miniconda3\\envs\\my\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Popen(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n","File \u001b[1;32md:\\miniconda3\\envs\\my\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_context\u001b[38;5;241m.\u001b[39mget_context()\u001b[38;5;241m.\u001b[39mProcess\u001b[38;5;241m.\u001b[39m_Popen(process_obj)\n","File \u001b[1;32md:\\miniconda3\\envs\\my\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Popen(process_obj)\n","File \u001b[1;32md:\\miniconda3\\envs\\my\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(process_obj, to_child)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n","File \u001b[1;32md:\\miniconda3\\envs\\my\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[38;5;241m.\u001b[39mdump(obj)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["exp = Exp(args) # 创建实验对象\n","print('>>>>>>>开始训练 : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","exp.train(setting) # 训练模型"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9-g_APi0wOSg","outputId":"22cf3059-d260-4429-fc1f-dc49b9aa37bd"},"outputs":[],"source":["# 进行训练和测试\n","if args.is_training:\n","    # 多次训练模型\n","    for ii in range(args.itr):\n","        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n","            args.task_name, # 任务名称\n","            args.model_id, # 模型id\n","            args.model, # 模型名称\n","            args.data, # 数据集名称\n","            args.features, # 预测任务\n","            args.seq_len, # 输入序列长度\n","            args.label_len, # 开始标记长度\n","            args.pred_len, # 预测序列长度\n","            args.d_model, # encoder 输入特征数\n","            args.n_heads, # 多头注意力机制\n","            args.e_layers, # encoder 层数\n","            args.d_layers, # decoder 层数\n","            args.d_ff, # FFN 层隐含神经元个数\n","            args.factor, # 对 Q 采样的因子数\n","            args.embed, # 时间特征嵌入方式\n","            args.distil, # 是否下采样操作 pooling\n","            args.des,  # 实验描述\n","            ii) # 实验轮数\n","\n","        exp = Exp(args) # 创建实验对象\n","        print('>>>>>>>开始训练 : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","        exp.train(setting) # 训练模型\n","\n","        print('>>>>>>>测试 : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","        exp.test(setting) # 测试模型\n","        if args.use_gpu:\n","            torch.cuda.empty_cache()\n","else:\n","    # 模型测试\n","    ii = 0\n","    setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n","        args.task_name,\n","        args.model_id,\n","        args.model,\n","        args.data,\n","        args.features,\n","        args.seq_len,\n","        args.label_len,\n","        args.pred_len,\n","        args.d_model,\n","        args.n_heads,\n","        args.e_layers,\n","        args.d_layers,\n","        args.d_ff,\n","        args.factor,\n","        args.embed,\n","        args.distil,\n","        args.des,\n","        ii)\n","    exp = Exp(args)  # 创建实验对象\n","    print('>>>>>>>测试 : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","    exp.test(setting, test=1) # 测试模型\n","    if args.use_gpu:\n","        torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t4lZaBhywOSi"},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir=./tensorboard_logs/"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
